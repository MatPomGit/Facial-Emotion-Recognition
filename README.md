# Facial-Emotion-Recognition

![Python Version](https://img.shields.io/badge/python-3.7%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![OpenCV](https://img.shields.io/badge/OpenCV-4.5%2B-red)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0.8%2B-orange)
![scikit--learn](https://img.shields.io/badge/scikit--learn-1.0%2B-yellow)

System rozpoznawania emocji na twarzy (FER - Facial Expression Recognition)

> **English**: Real-time facial emotion recognition system using MediaPipe for face detection and SVM for emotion classification. Detects 7 basic emotions: angry, disgust, fear, happy, neutral, sad, surprise.
>
> **Polski**: System rozpoznawania emocji na twarzy w czasie rzeczywistym wykorzystujcy MediaPipe do wykrywania twarzy i SVM do klasyfikacji emocji. Wykrywa 7 podstawowych emocji: zo, obrzydzenie, strach, rado, neutralno, smutek, zaskoczenie.

## Wprowadzenie dla student贸w
Ten projekt to praktyczna implementacja systemu do rozpoznawania emocji na ludzkich twarzach. Jeli dopiero zaczynasz przygod z machine learning i computer vision, ten projekt pomo偶e Ci zrozumie podstawowe koncepcje:
- Wykrywanie twarzy na obrazie
- Ekstrakcja cech charakterystycznych z twarzy
- Trenowanie modelu uczenia maszynowego
- Predykcja emocji w czasie rzeczywistym

## Modele wykorzystywane w projekcie
(#) oznacza aktualnie u偶ywany model

### A. Wykrywanie twarzy na obrazie
Pierwszym krokiem jest zlokalizowanie twarzy na obrazie. Wykorzystujemy do tego nastpujce metody:

#### Dlib HoG Face Detection
**Co to jest?** Dlib to biblioteka zawierajca algorytm wykrywania twarzy oparty na metodzie HoG (Histogram of Oriented Gradients).

**Zalety:** Model jest stosunkowo szybki i dobrze sprawdza si w podstawowych zastosowaniach.

**Wady:** Jest to starsza technologia. Dokadno nie jest tak dobra jak w nowszych modelach opartych na sieciach neuronowych. Model ma r贸wnie偶 problemy z wykrywaniem twarzy pod ktem lub w trudnych warunkach owietleniowych.

#### Mediapipe Deep Learning-based Face Detection (#)
**Co to jest?** Mediapipe to biblioteka od Google wykorzystujca gbokie sieci neuronowe do wykrywania twarzy.

**Zalety:** Bardzo wysoka dokadno, szybkie dziaanie, wietnie radzi sobie z r贸偶nymi ktami i pozycjami twarzy.

**Wady:** Czasami wykrywa bardzo szczeg贸owe punkty charakterystyczne, co mo偶e spowolni dziaanie systemu lub by zbdne dla prostszych zastosowa.

**Dlaczego to wybralimy?** Ten model jest obecnie u偶ywany w projekcie ze wzgldu na lepsz dokadno i nowoczesne podejcie.

### B. Rozpoznawanie emocji
Po wykryciu twarzy, system musi okreli emocj. U偶ywamy do tego:

#### Support Vector Machines (SVM) (#)
**Co to jest?** SVM to algorytm uczenia maszynowego, kt贸ry uczy si rozpoznawa wzorce na podstawie przykadowych danych.

**Jak to dziaa?** System analizuje proporcje twarzy (np. szeroko umiechu, otwarcie oczu, pozycj brwi) i na tej podstawie klasyfikuje emocj.

**Rozpoznawane emocje:** angry (zo), disgust (obrzydzenie), fear (strach), happy (rado), neutral (neutralno), sad (smutek), surprise (zaskoczenie)

**Ograniczenia:** Model dobrze radzi sobie z wikszoci emocji, ale ma trudnoci z rozr贸偶nieniem emocji o podobnych proporcjach twarzy (np. strach i zaskoczenie mog by czasem mylone).

## Instrukcja krok po kroku

### Krok 1: Przygotowanie zbioru danych z emocjami
**Cel:** Stworzy plik CSV zawierajcy proporcje twarzy dla r贸偶nych emocji, kt贸ry posu偶y do trenowania modelu.

**Co musisz wiedzie:**
- Projekt wymaga zbioru danych ze zdjciami twarzy wyra偶ajcych r贸偶ne emocje
- Zdjcia powinny by pogrupowane w foldery wedug emocji (np. `dataset/train/happy/`, `dataset/train/sad/`)
- System automatycznie przetworzy te zdjcia i wyekstrahuje z nich cechy charakterystyczne

**Dostpne moduy:**
1. **Modu dlib:** `modules/dlib/`
   - Starszy, ale nadal funkcjonalny system wykrywania punkt贸w charakterystycznych twarzy
   - U偶ywa 68 punkt贸w orientacyjnych na twarzy

2. **Modu mediapipe:** `modules/mediapipe/` (ZALECANY)
   - Nowszy, bardziej dokadny system
   - U偶ywa 468 punkt贸w orientacyjnych na twarzy

**Pliki w ka偶dym module:**
- `dataset_prepare.py` - G贸wny skrypt do przetwarzania zdj i tworzenia zbioru danych
  * Wczytuje zdjcia z folder贸w
  * Wykrywa twarze na ka偶dym zdjciu
  * Oblicza proporcje charakterystyczne
  * Zapisuje wyniki do pliku CSV

- `mediapipe_FaceLandmarks.py` lub `dlib_FaceLandmarks.py` - Kod odpowiedzialny za wykrywanie twarzy i punkt贸w charakterystycznych

- `ratio_calc.py` - Oblicza proporcje twarzy (np. stosunek szerokoci ust do szerokoci twarzy)
  * Szczeg贸owy opis obliczanych proporcji znajduje si w komentarzach w pliku
  * System oblicza 8 r贸偶nych proporcji (a1-a8) na podstawie odlegoci midzy punktami twarzy

**Wynik:** Plik CSV w folderze `dataset/` (np. `mediapipe_train_emotions.csv`) zawierajcy:
- Kolumny z wartociami proporcji (8 wartoci liczbowych)
- Kolumna z etykiet emocji (angry, happy, sad, itd.)

### Krok 2: Trenowanie modelu rozpoznawania emocji
**Cel:** Nauczy model SVM rozpoznawa emocje na podstawie proporcji twarzy.

**G贸wny plik:** `main.py`
- Uruchamia kamer lub wczytuje zdjcie
- aduje wytrenowany model SVM
- Wykrywa twarze w czasie rzeczywistym
- Przewiduje emocje
- Wywietla wyniki

**Pomocnicze moduy:**
- `modules/svm.py` - Implementacja algorytmu SVM
  * Wczytuje dane z pliku CSV
  * Trenuje model na podstawie przykad贸w
  * Dokonuje predykcji emocji dla nowych danych
  
- `modules/fps.py` - Oblicza i wywietla liczb klatek na sekund (FPS)
  * Pomaga monitorowa wydajno systemu
  * Im wy偶sze FPS, tym pynniejsze dziaanie

**Jak to dziaa:**
1. Program uruchamia kamer i pobiera obraz
2. System wykrywa wszystkie twarze na obrazie
3. Dla ka偶dej twarzy oblicza proporcje
4. Model SVM analizuje proporcje i przewiduje emocj
5. Wynik jest wywietlany na ekranie i w terminalu
6. Proces powtarza si dla ka偶dej klatki wideo

**Wynik:** Okno z podgldem kamery, gdzie widoczne s:
- Wykryte punkty charakterystyczne twarzy (niebieskie kropki)
- Numer rozpoznanej twarzy
- FPS w lewym g贸rnym rogu
- W terminalu: przewidywane wartoci liczbowe i nazwy emocji

##  Szybki start / Quick Start

### Instalacja / Installation

```bash
# Sklonuj repozytorium / Clone the repository
git clone https://github.com/MatPomGit/Facial-Emotion-Recognition.git
cd Facial-Emotion-Recognition

# Zainstaluj zale偶noci / Install dependencies
pip install -r requirements.txt

# Lub zainstaluj jako pakiet / Or install as package
pip install -e .
```

### Pierwsze uruchomienie / First Run

```bash
# Uruchom program z domyln kamer / Run with default camera
python main.py
```

Nacinij `q` aby zakoczy / Press `q` to quit

##  Wymagania techniczne / Requirements

- Python 3.7+
- Biblioteki / Libraries:
  - OpenCV (opencv-python) >= 4.5.0
  - MediaPipe >= 0.8.10
  - scikit-learn >= 1.0.0
  - pandas >= 1.3.0
  - numpy >= 1.21.0
- Kamera internetowa (opcjonalnie) / Webcam (optional)
- Zbi贸r danych z emocjami / Emotion dataset

Pena lista zale偶noci w `requirements.txt` / Full dependency list in `requirements.txt`

## Wskaz贸wki dla pocztkujcych
1. **Zacznij od maego zbioru danych** - Nie potrzebujesz tysicy zdj na pocztku. Zacznij od kilkudziesiciu zdj na ka偶d emocj, 偶eby zrozumie jak dziaa system.

2. **Eksperymentuj z parametrami** - W pliku `main.py` mo偶esz zmienia parametry jak `samples_limit` czy `kernel`, 偶eby zobaczy jak wpywaj na wyniki.

3. **Obserwuj FPS** - Jeli program dziaa wolno, zmniejsz liczb wykrywanych punkt贸w lub u偶yj prostszego modelu.

4. **Testuj r贸偶ne emocje** - Spr贸buj r贸偶nych wyraz贸w twarzy przed kamer i zobacz jak model reaguje.

5. **Czytaj komentarze w kodzie** - Ka偶dy plik zawiera szczeg贸owe komentarze wyjaniajce co robi poszczeg贸lny fragment kodu.

##  Dokumentacja / Documentation

- **[PRZEWODNIK_DLA_STUDENTA.md](PRZEWODNIK_DLA_STUDENTA.md)** - Kompleksowy przewodnik dla student贸w i pocztkujcych / Comprehensive student guide
- **[CONTRIBUTING.md](CONTRIBUTING.md)** - Jak pom贸c w rozwoju projektu / How to contribute
- **[CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md)** - Kodeks postpowania / Code of conduct
- **[CHANGELOG.md](CHANGELOG.md)** - Historia zmian / Change history

##  Jak pom贸c? / How to Contribute?

Zapraszamy do wsp贸pracy! Zobacz [CONTRIBUTING.md](CONTRIBUTING.md) po wicej informacji.

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for more information.

##  Licencja / License

Ten projekt jest dostpny na licencji MIT. Zobacz plik [LICENSE](LICENSE) po szczeg贸y.

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

##  Kontakt / Contact

- GitHub Issues: [Report a bug or request a feature](https://github.com/MatPomGit/Facial-Emotion-Recognition/issues)
- Pull Requests: [Contribute to the project](https://github.com/MatPomGit/Facial-Emotion-Recognition/pulls)

##  Podzikowania / Acknowledgments

- Google MediaPipe team - za doskona bibliotek do wykrywania twarzy
- Tw贸rcy scikit-learn - za implementacj algorytmu SVM
- Spoeczno OpenCV - za wszechstronne narzdzia do przetwarzania obrazu

---

**Stworzone z わ dla edukacji i nauki / Made with わ for education and learning**