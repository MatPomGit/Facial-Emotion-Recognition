# Facial-Emotion-Recognition

![Python Version](https://img.shields.io/badge/python-3.7%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![OpenCV](https://img.shields.io/badge/OpenCV-4.5%2B-red)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0.8%2B-orange)
![scikit--learn](https://img.shields.io/badge/scikit--learn-1.0%2B-yellow)
![Status](https://img.shields.io/badge/status-active-success)

System rozpoznawania emocji na twarzy (FER - Facial Expression Recognition)

> **English**: Real-time facial emotion recognition system using MediaPipe for face detection and SVM for emotion classification. Detects 7 basic emotions: angry, disgust, fear, happy, neutral, sad, surprise.
>
> **Polski**: System rozpoznawania emocji na twarzy w czasie rzeczywistym wykorzystujÄ…cy MediaPipe do wykrywania twarzy i SVM do klasyfikacji emocji. Wykrywa 7 podstawowych emocji: zÅ‚oÅ›Ä‡, obrzydzenie, strach, radoÅ›Ä‡, neutralnoÅ›Ä‡, smutek, zaskoczenie.

## Wprowadzenie dla studentÃ³w
Ten projekt to praktyczna implementacja systemu do rozpoznawania emocji na ludzkich twarzach. JeÅ›li dopiero zaczynasz przygodÄ™ z machine learning i computer vision, ten projekt pomoÅ¼e Ci zrozumieÄ‡ podstawowe koncepcje:
- Wykrywanie twarzy na obrazie
- Ekstrakcja cech charakterystycznych z twarzy
- Trenowanie modelu uczenia maszynowego
- Predykcja emocji w czasie rzeczywistym

## Modele wykorzystywane w projekcie
(#) oznacza aktualnie uÅ¼ywany model

### A. Wykrywanie twarzy na obrazie
Pierwszym krokiem jest zlokalizowanie twarzy na obrazie. Wykorzystujemy do tego nastÄ™pujÄ…ce metody:

#### Dlib HoG Face Detection
**Co to jest?** Dlib to biblioteka zawierajÄ…ca algorytm wykrywania twarzy oparty na metodzie HoG (Histogram of Oriented Gradients).

**Zalety:** Model jest stosunkowo szybki i dobrze sprawdza siÄ™ w podstawowych zastosowaniach.

**Wady:** Jest to starsza technologia. DokÅ‚adnoÅ›Ä‡ nie jest tak dobra jak w nowszych modelach opartych na sieciach neuronowych. Model ma rÃ³wnieÅ¼ problemy z wykrywaniem twarzy pod kÄ…tem lub w trudnych warunkach oÅ›wietleniowych.

#### Mediapipe Deep Learning-based Face Detection (#)
**Co to jest?** Mediapipe to biblioteka od Google wykorzystujÄ…ca gÅ‚Ä™bokie sieci neuronowe do wykrywania twarzy.

**Zalety:** Bardzo wysoka dokÅ‚adnoÅ›Ä‡, szybkie dziaÅ‚anie, Å›wietnie radzi sobie z rÃ³Å¼nymi kÄ…tami i pozycjami twarzy.

**Wady:** Czasami wykrywa bardzo szczegÃ³Å‚owe punkty charakterystyczne, co moÅ¼e spowolniÄ‡ dziaÅ‚anie systemu lub byÄ‡ zbÄ™dne dla prostszych zastosowaÅ„.

**Dlaczego to wybraliÅ›my?** Ten model jest obecnie uÅ¼ywany w projekcie ze wzglÄ™du na lepszÄ… dokÅ‚adnoÅ›Ä‡ i nowoczesne podejÅ›cie.

### B. Rozpoznawanie emocji
Po wykryciu twarzy, system musi okreÅ›liÄ‡ emocjÄ™. UÅ¼ywamy do tego:

#### Support Vector Machines (SVM) (#)
**Co to jest?** SVM to algorytm uczenia maszynowego, ktÃ³ry uczy siÄ™ rozpoznawaÄ‡ wzorce na podstawie przykÅ‚adowych danych.

**Jak to dziaÅ‚a?** System analizuje proporcje twarzy (np. szerokoÅ›Ä‡ uÅ›miechu, otwarcie oczu, pozycjÄ™ brwi) i na tej podstawie klasyfikuje emocjÄ™.

**Rozpoznawane emocje:** angry (zÅ‚oÅ›Ä‡), disgust (obrzydzenie), fear (strach), happy (radoÅ›Ä‡), neutral (neutralnoÅ›Ä‡), sad (smutek), surprise (zaskoczenie)

**Ograniczenia:** Model dobrze radzi sobie z wiÄ™kszoÅ›ciÄ… emocji, ale ma trudnoÅ›ci z rozrÃ³Å¼nieniem emocji o podobnych proporcjach twarzy (np. strach i zaskoczenie mogÄ… byÄ‡ czasem mylone).

## Instrukcja krok po kroku

### Krok 1: Przygotowanie zbioru danych z emocjami
**Cel:** StworzyÄ‡ plik CSV zawierajÄ…cy proporcje twarzy dla rÃ³Å¼nych emocji, ktÃ³ry posÅ‚uÅ¼y do trenowania modelu.

**Co musisz wiedzieÄ‡:**
- Projekt wymaga zbioru danych ze zdjÄ™ciami twarzy wyraÅ¼ajÄ…cych rÃ³Å¼ne emocje
- ZdjÄ™cia powinny byÄ‡ pogrupowane w foldery wedÅ‚ug emocji (np. `dataset/train/happy/`, `dataset/train/sad/`)
- System automatycznie przetworzy te zdjÄ™cia i wyekstrahuje z nich cechy charakterystyczne

**DostÄ™pne moduÅ‚y:**
1. **ModuÅ‚ dlib:** `modules/dlib/`
   - Starszy, ale nadal funkcjonalny system wykrywania punktÃ³w charakterystycznych twarzy
   - UÅ¼ywa 68 punktÃ³w orientacyjnych na twarzy

2. **ModuÅ‚ mediapipe:** `modules/mediapipe/` (ZALECANY)
   - Nowszy, bardziej dokÅ‚adny system
   - UÅ¼ywa 468 punktÃ³w orientacyjnych na twarzy

**Pliki w kaÅ¼dym module:**
- `dataset_prepare.py` - GÅ‚Ã³wny skrypt do przetwarzania zdjÄ™Ä‡ i tworzenia zbioru danych
  * Wczytuje zdjÄ™cia z folderÃ³w
  * Wykrywa twarze na kaÅ¼dym zdjÄ™ciu
  * Oblicza proporcje charakterystyczne
  * Zapisuje wyniki do pliku CSV

- `mediapipe_FaceLandmarks.py` lub `dlib_FaceLandmarks.py` - Kod odpowiedzialny za wykrywanie twarzy i punktÃ³w charakterystycznych

- `ratio_calc.py` - Oblicza proporcje twarzy (np. stosunek szerokoÅ›ci ust do szerokoÅ›ci twarzy)
  * SzczegÃ³Å‚owy opis obliczanych proporcji znajduje siÄ™ w komentarzach w pliku
  * System oblicza 8 rÃ³Å¼nych proporcji (a1-a8) na podstawie odlegÅ‚oÅ›ci miÄ™dzy punktami twarzy

**Wynik:** Plik CSV w folderze `dataset/` (np. `mediapipe_train_emotions.csv`) zawierajÄ…cy:
- Kolumny z wartoÅ›ciami proporcji (8 wartoÅ›ci liczbowych)
- Kolumna z etykietÄ… emocji (angry, happy, sad, itd.)

### Krok 2: Trenowanie modelu rozpoznawania emocji
**Cel:** NauczyÄ‡ model SVM rozpoznawaÄ‡ emocje na podstawie proporcji twarzy.

**GÅ‚Ã³wny plik:** `main.py`
- Uruchamia kamerÄ™ lub wczytuje zdjÄ™cie
- Åaduje wytrenowany model SVM
- Wykrywa twarze w czasie rzeczywistym
- Przewiduje emocje
- WyÅ›wietla wyniki

**Pomocnicze moduÅ‚y:**
- `modules/svm.py` - Implementacja algorytmu SVM
  * Wczytuje dane z pliku CSV
  * Trenuje model na podstawie przykÅ‚adÃ³w
  * Dokonuje predykcji emocji dla nowych danych
  
- `modules/fps.py` - Oblicza i wyÅ›wietla liczbÄ™ klatek na sekundÄ™ (FPS)
  * Pomaga monitorowaÄ‡ wydajnoÅ›Ä‡ systemu
  * Im wyÅ¼sze FPS, tym pÅ‚ynniejsze dziaÅ‚anie

**Jak to dziaÅ‚a:**
1. Program uruchamia kamerÄ™ i pobiera obraz
2. System wykrywa wszystkie twarze na obrazie
3. Dla kaÅ¼dej twarzy oblicza proporcje
4. Model SVM analizuje proporcje i przewiduje emocjÄ™
5. Wynik jest wyÅ›wietlany na ekranie i w terminalu
6. Proces powtarza siÄ™ dla kaÅ¼dej klatki wideo

**Wynik:** Okno z podglÄ…dem kamery, gdzie widoczne sÄ…:
- Wykryte punkty charakterystyczne twarzy (niebieskie kropki)
- Numer rozpoznanej twarzy
- FPS w lewym gÃ³rnym rogu
- W terminalu: przewidywane wartoÅ›ci liczbowe i nazwy emocji

## ğŸš€ Szybki start / Quick Start

### Instalacja / Installation

```bash
# Sklonuj repozytorium / Clone the repository
git clone https://github.com/MatPomGit/Facial-Emotion-Recognition.git
cd Facial-Emotion-Recognition

# Zainstaluj zaleÅ¼noÅ›ci / Install dependencies
pip install -r requirements.txt

# Lub zainstaluj jako pakiet / Or install as package
pip install -e .
```

### Pierwsze uruchomienie / First Run

```bash
# Uruchom program z domyÅ›lnÄ… kamerÄ… / Run with default camera
python main.py
```

NaciÅ›nij `q` aby zakoÅ„czyÄ‡ / Press `q` to quit

## ğŸ“‹ Wymagania techniczne / Requirements

- Python 3.7+
- Biblioteki / Libraries:
  - OpenCV (opencv-python) >= 4.5.0
  - MediaPipe >= 0.8.10
  - scikit-learn >= 1.0.0
  - pandas >= 1.3.0
  - numpy >= 1.21.0
- Kamera internetowa (opcjonalnie) / Webcam (optional)
- ZbiÃ³r danych z emocjami / Emotion dataset

PeÅ‚na lista zaleÅ¼noÅ›ci w `requirements.txt` / Full dependency list in `requirements.txt`

## WskazÃ³wki dla poczÄ…tkujÄ…cych
1. **Zacznij od maÅ‚ego zbioru danych** - Nie potrzebujesz tysiÄ™cy zdjÄ™Ä‡ na poczÄ…tku. Zacznij od kilkudziesiÄ™ciu zdjÄ™Ä‡ na kaÅ¼dÄ… emocjÄ™, Å¼eby zrozumieÄ‡ jak dziaÅ‚a system.

2. **Eksperymentuj z parametrami** - W pliku `main.py` moÅ¼esz zmieniaÄ‡ parametry jak `samples_limit` czy `kernel`, Å¼eby zobaczyÄ‡ jak wpÅ‚ywajÄ… na wyniki.

3. **Obserwuj FPS** - JeÅ›li program dziaÅ‚a wolno, zmniejsz liczbÄ™ wykrywanych punktÃ³w lub uÅ¼yj prostszego modelu.

4. **Testuj rÃ³Å¼ne emocje** - SprÃ³buj rÃ³Å¼nych wyrazÃ³w twarzy przed kamerÄ… i zobacz jak model reaguje.

5. **Czytaj komentarze w kodzie** - KaÅ¼dy plik zawiera szczegÃ³Å‚owe komentarze wyjaÅ›niajÄ…ce co robi poszczegÃ³lny fragment kodu.

## ğŸ“š Dokumentacja / Documentation

- **[SZYBKI_START.md](SZYBKI_START.md)** âš¡ - Start w 5 minut! / Get started in 5 minutes!
- **[README.md](README.md)** - Ten plik / This file - Project overview
- **[INSTALACJA.md](INSTALACJA.md)** - SzczegÃ³Å‚owa instrukcja instalacji / Detailed installation guide  
- **[PRZEWODNIK_DLA_STUDENTA.md](PRZEWODNIK_DLA_STUDENTA.md)** - Kompleksowy przewodnik dla studentÃ³w i poczÄ…tkujÄ…cych / Comprehensive student guide
- **[ARCHITEKTURA.md](ARCHITEKTURA.md)** - Dokumentacja architektury systemu / System architecture documentation
- **[API.md](API.md)** - Dokumentacja API i przykÅ‚ady uÅ¼ycia / API documentation and usage examples
- **[CONTRIBUTING.md](CONTRIBUTING.md)** - Jak pomÃ³c w rozwoju projektu / How to contribute
- **[CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md)** - Kodeks postÄ™powania / Code of conduct
- **[CHANGELOG.md](CHANGELOG.md)** - Historia zmian / Change history

## ğŸ¤ Jak pomÃ³c? / How to Contribute?

Zapraszamy do wspÃ³Å‚pracy! Zobacz [CONTRIBUTING.md](CONTRIBUTING.md) po wiÄ™cej informacji.

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for more information.

## ğŸ“œ Licencja / License

Ten projekt jest dostÄ™pny na licencji MIT. Zobacz plik [LICENSE](LICENSE) po szczegÃ³Å‚y.

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸ“ Kontakt / Contact

- GitHub Issues: [Report a bug or request a feature](https://github.com/MatPomGit/Facial-Emotion-Recognition/issues)
- Pull Requests: [Contribute to the project](https://github.com/MatPomGit/Facial-Emotion-Recognition/pulls)

## ğŸ™ PodziÄ™kowania / Acknowledgments

- Google MediaPipe team - za doskonaÅ‚Ä… bibliotekÄ™ do wykrywania twarzy
- TwÃ³rcy scikit-learn - za implementacjÄ™ algorytmu SVM
- SpoÅ‚ecznoÅ›Ä‡ OpenCV - za wszechstronne narzÄ™dzia do przetwarzania obrazu

---

**Stworzone z â¤ï¸ dla edukacji i nauki / Made with â¤ï¸ for education and learning**