# Przewodnik dla Studenta - Rozpoznawanie Emocji na Twarzy

## ğŸ“ Witaj w projekcie!

Ten dokument zostaÅ‚ stworzony specjalnie dla osÃ³b, ktÃ³re po raz pierwszy majÄ… kontakt z systemami rozpoznawania emocji. Przeprowadzimy CiÄ™ krok po kroku przez caÅ‚y proces.

---

## ğŸ“š Spis TreÅ›ci

1. [Czym jest ten projekt?](#czym-jest-ten-projekt)
2. [Wymagania wstÄ™pne](#wymagania-wstÄ™pne)
3. [Instalacja krok po kroku](#instalacja-krok-po-kroku)
4. [Jak dziaÅ‚a system?](#jak-dziaÅ‚a-system)
5. [Pierwsze uruchomienie](#pierwsze-uruchomienie)
6. [Rozumienie wynikÃ³w](#rozumienie-wynikÃ³w)
7. [Eksperymenty do przeprowadzenia](#eksperymenty-do-przeprowadzenia)
8. [RozwiÄ…zywanie problemÃ³w](#rozwiÄ…zywanie-problemÃ³w)
9. [Dalsza nauka](#dalsza-nauka)

---

## ğŸ¯ Czym jest ten projekt?

To praktyczny system, ktÃ³ry:
- **Wykrywa twarze** na obrazie z kamery lub zdjÄ™cia
- **Analizuje charakterystyczne punkty** twarzy (np. kÄ…ciki ust, oczy, brwi)
- **Rozpoznaje emocjÄ™** uÅ¼ywajÄ…c algorytmu uczenia maszynowego
- **Pokazuje wyniki** w czasie rzeczywistym

### Jakie emocje rozpoznaje?

System rozpoznaje 7 podstawowych emocji:
1. **angry** (zÅ‚oÅ›Ä‡) - Å›ciÄ…gniÄ™te brwi, zaciÅ›niÄ™te usta
2. **disgust** (obrzydzenie) - pomarszczony nos, uniesiona gÃ³rna warga
3. **fear** (strach) - szeroko otwarte oczy, napiÄ™ta twarz
4. **happy** (radoÅ›Ä‡) - szeroki uÅ›miech, przymruÅ¼one oczy
5. **neutral** (neutralnoÅ›Ä‡) - spokojna, niewyraÅºna ekspresja
6. **sad** (smutek) - opuszczone kÄ…ciki ust, smutne oczy
7. **surprise** (zaskoczenie) - szeroko otwarte oczy i usta

---

## ğŸ’» Wymagania wstÄ™pne

### Co musisz wiedzieÄ‡ przed rozpoczÄ™ciem:

**Poziom podstawowy:**
- Podstawy programowania w Pythonie (zmienne, pÄ™tle, funkcje)
- UmiejÄ™tnoÅ›Ä‡ korzystania z terminala/wiersza poleceÅ„
- Podstawowe pojÄ™cia o tym czym jest uczenie maszynowe (opcjonalne, wyjaÅ›nimy po drodze)

**Co musisz mieÄ‡ na komputerze:**
- Python 3.7 lub nowszy
- Pip (menedÅ¼er pakietÃ³w Python)
- Kamera internetowa (jeÅ›li chcesz testowaÄ‡ na Å¼ywo)
- OkoÅ‚o 2GB wolnego miejsca na dysku

---

## ğŸ› ï¸ Instalacja krok po kroku

### Krok 1: Sklonuj repozytorium

OtwÃ³rz terminal i wykonaj:

```bash
git clone https://github.com/MatPomGit/Facial-Emotion-Recognition.git
cd Facial-Emotion-Recognition
```

**Co siÄ™ staÅ‚o?** PobraÅ‚eÅ› wszystkie pliki projektu na swÃ³j komputer.

### Krok 2: Zainstaluj wymagane biblioteki

```bash
pip install opencv-python mediapipe scikit-learn pandas numpy
```

**Co instalujemy?**
- `opencv-python` - przetwarzanie obrazu i wideo
- `mediapipe` - wykrywanie punktÃ³w charakterystycznych twarzy (od Google)
- `scikit-learn` - algorytmy uczenia maszynowego (SVM)
- `pandas` - operacje na danych (wczytywanie CSV)
- `numpy` - operacje matematyczne na tablicach

**Jak dÅ‚ugo to trwa?** 2-5 minut, w zaleÅ¼noÅ›ci od prÄ™dkoÅ›ci internetu.

### Krok 3: Pobierz zbiÃ³r danych

Potrzebujesz zbioru zdjÄ™Ä‡ twarzy z emocjami do wytrenowania modelu.

**Zalecany zbiÃ³r danych:** FER-2013 lub podobny

Zorganizuj pliki w nastÄ™pujÄ…cej strukturze:
```
dataset/
  train/
    angry/
      image1.jpg
      image2.jpg
      ...
    happy/
      image1.jpg
      image2.jpg
      ...
    (pozostaÅ‚e emocje...)
```

**WskazÃ³wka:** MoÅ¼esz zaczÄ…Ä‡ od maÅ‚ego zbioru (50 zdjÄ™Ä‡ na emocjÄ™) do testÃ³w!

---

## ğŸ§  Jak dziaÅ‚a system?

System dziaÅ‚a w 3 gÅ‚Ã³wnych etapach:

### Etap 1: Przygotowanie danych treningowych

**Plik:** `modules/mediapipe/dataset_prepare.py`

**Co siÄ™ dzieje:**
```
ZdjÄ™cia twarzy â†’ Wykrycie twarzy â†’ Zmierzenie punktÃ³w â†’ Obliczenie proporcji â†’ CSV
```

**SzczegÃ³Å‚y:**
1. Program czyta zdjÄ™cia z folderÃ³w `dataset/train/`
2. Dla kaÅ¼dego zdjÄ™cia wykrywa twarz uÅ¼ywajÄ…c MediaPipe
3. Znajduje 468 punktÃ³w charakterystycznych
4. Oblicza 8 kluczowych proporcji (np. szerokoÅ›Ä‡ uÅ›miechu / szerokoÅ›Ä‡ twarzy)
5. Zapisuje wyniki do pliku CSV wraz z etykietÄ… emocji

**Proporcje zamiast surowych punktÃ³w - dlaczego?**
- 468 punktÃ³w Ã— 3 wspÃ³Å‚rzÄ™dne = 1404 wartoÅ›ci!
- 8 proporcji jest Å‚atwiejsze do analizy
- Proporcje sÄ… niezaleÅ¼ne od wielkoÅ›ci twarzy i odlegÅ‚oÅ›ci od kamery

### Etap 2: Trenowanie modelu

**Plik:** `modules/svm.py`

**Co siÄ™ dzieje:**
```
Dane CSV â†’ Przygotowanie â†’ Algorytm SVM â†’ Wytrenowany model
```

**SzczegÃ³Å‚y:**
1. Wczytanie danych z CSV (8 proporcji + etykieta emocji)
2. PodziaÅ‚ na cechy (X) i etykiety (y)
3. Opcjonalna normalizacja danych
4. Balansowanie zbioru (rÃ³wna liczba przykÅ‚adÃ³w dla kaÅ¼dej emocji)
5. Trenowanie modelu SVM
6. Model gotowy do przewidywania!

**Co to jest SVM?**
Support Vector Machine to algorytm, ktÃ³ry uczy siÄ™ rozpoznawaÄ‡ wzorce:
- Dostaje przykÅ‚ady: "te proporcje = radoÅ›Ä‡", "tamte proporcje = smutek"
- Znajduje "granice" miÄ™dzy rÃ³Å¼nymi emocjami w przestrzeni cech
- Nowe przykÅ‚ady klasyfikuje na podstawie znalezionych granic

### Etap 3: Rozpoznawanie w czasie rzeczywistym

**Plik:** `main.py`

**Co siÄ™ dzieje:**
```
Kamera â†’ Klatka â†’ Wykryj twarz â†’ Oblicz proporcje â†’ Model przewiduje â†’ WyÅ›wietl
```

**PÄ™tla gÅ‚Ã³wna powtarza siÄ™ ciÄ…gle:**
1. Pobierz klatkÄ™ z kamery
2. Wykryj wszystkie twarze (MediaPipe)
3. Dla kaÅ¼dej twarzy oblicz 8 proporcji
4. Zapytaj model SVM o emocjÄ™
5. WyÅ›wietl wynik na ekranie i w terminalu
6. WrÃ³Ä‡ do kroku 1

---

## ğŸš€ Pierwsze uruchomienie

### Opcja A: Przygotuj wÅ‚asne dane treningowe (polecane dla nauki)

```bash
# PrzejdÅº do folderu mediapipe
cd modules/mediapipe

# Uruchom skrypt przygotowania danych
python dataset_prepare.py
```

**Czego oczekiwaÄ‡:**
- Pasek postÄ™pu pokazujÄ…cy przetwarzanie zdjÄ™Ä‡
- Komunikaty o wykrytych twarzach
- Plik CSV z wynikami w `dataset/mediapipe_train_emotions.csv`

### Opcja B: UÅ¼yj gotowego pliku CSV (jeÅ›li juÅ¼ masz)

Upewnij siÄ™, Å¼e plik `dataset/mediapipe_train_emotions.csv` istnieje i jest poprawnie sformatowany.

### Uruchom program gÅ‚Ã³wny

```bash
# WrÃ³Ä‡ do katalogu gÅ‚Ã³wnego
cd ../..

# Uruchom program
python main.py
```

**Co zobaczysz:**
1. Komunikaty o inicjalizacji modelu
2. Informacje o trenowaniu (moÅ¼e potrwaÄ‡ 10-60 sekund)
3. Okno z podglÄ…dem kamery
4. Niebieskie kropki na wykrytych twarzach
5. FPS w lewym gÃ³rnym rogu
6. W terminalu: przewidywane emocje

**Aby zakoÅ„czyÄ‡:** NaciÅ›nij klawisz `q` (quit)

---

## ğŸ“Š Rozumienie wynikÃ³w

### Okno podglÄ…du

**Niebieskie kropki:** Wszystkie 468 punktÃ³w wykrytych przez MediaPipe
**Czerwona cyfra:** Numer twarzy (gdy wykryto wiele osÃ³b)
**Zielony tekst (FPS):** Liczba klatek na sekundÄ™

### Terminal/konsola

PrzykÅ‚adowy wynik:
```
[3.14159] - ['happy']
```

**Interpretacja:**
- `3.14159` - surowa wartoÅ›Ä‡ przewidywana przez SVM (0-6)
- `happy` - emocja odpowiadajÄ…ca wartoÅ›ci 3 (po zaokrÄ…gleniu)

**Mapowanie liczb na emocje:**
```
0 â†’ angry
1 â†’ disgust
2 â†’ fear
3 â†’ happy
4 â†’ neutral
5 â†’ sad
6 â†’ surprise
```

**WartoÅ›ci poÅ›rednie:**
- `3.2` = przewaÅ¼nie happy, odrobinÄ™ neutral
- `2.8` = miÄ™dzy fear a happy
- `5.9` = prawie surprise

---

## ğŸ”¬ Eksperymenty do przeprowadzenia

Nauka wymaga eksperymentowania! Oto zadania do samodzielnego wykonania:

### Eksperyment 1: Testuj rÃ³Å¼ne emocje

**Zadanie:** Postaw przed kamerÄ… i sprÃ³buj wyraziÄ‡ kaÅ¼dÄ… z 7 emocji.

**Pytania do przemyÅ›lenia:**
- KtÃ³re emocje sÄ… najÅ‚atwiej rozpoznawane?
- KtÃ³re sÄ… mylone ze sobÄ…?
- Czy model radzi sobie z subtelnym wyrazami twarzy?

### Eksperyment 2: Zmiana parametrÃ³w SVM

**Plik:** `main.py`, linia z `emotion_model.train()`

**Zadania:**
1. ZmieÅ„ `kernel='rbf'` na `kernel='poly'` - jak zmienia siÄ™ dokÅ‚adnoÅ›Ä‡?
2. ZmieÅ„ `samples_limit=3000` na `samples_limit=1000` - czy model dziaÅ‚a lepiej czy gorzej?
3. ZmieÅ„ `scale=False` na `scale=True` - jaki to ma wpÅ‚yw?

### Eksperyment 3: Optymalizacja wydajnoÅ›ci

**Zadanie:** SprawdÅº FPS przed i po zmianach.

**Zmiany do przetestowania w `main.py`:**
1. ZmieÅ„ `fx=1, fy=1` na `fx=0.5, fy=0.5` (mniejsza rozdzielczoÅ›Ä‡)
2. ZmieÅ„ `max_face=10` na `max_face=1` (jedna twarz zamiast dziesiÄ™ciu)
3. Zakomentuj pÄ™tlÄ™ rysujÄ…cÄ… 468 punktÃ³w (linie 49-52)

**Pytania:**
- Jak kaÅ¼da zmiana wpÅ‚ywa na FPS?
- Czy dokÅ‚adnoÅ›Ä‡ rozpoznawania siÄ™ zmienia?

### Eksperyment 4: PorÃ³wnaj MediaPipe z Dlib

**Zadanie:** Uruchom system z moduÅ‚em dlib zamiast mediapipe.

**Kroki:**
1. ZmieÅ„ importy w `main.py`:
   ```python
   # Zamiast mediapipe:
   from modules.dlib.dlib_FaceLandmarks import FaceDetector
   from modules.dlib.ratio_calc import RatioCalculator
   ```
2. UÅ¼yj odpowiedniego pliku CSV (dlib_train_emotions.csv)

**PorÃ³wnaj:**
- SzybkoÅ›Ä‡ (FPS)
- DokÅ‚adnoÅ›Ä‡ rozpoznawania
- StabilnoÅ›Ä‡ wykrywania

---

## ğŸ› RozwiÄ…zywanie problemÃ³w

### Problem: "Cannot find file path" przy uruchamianiu

**RozwiÄ…zanie:**
- SprawdÅº czy plik CSV istnieje: `dataset/mediapipe_train_emotions.csv`
- Upewnij siÄ™ Å¼e uruchamiasz program z gÅ‚Ã³wnego katalogu projektu

### Problem: Bardzo niskie FPS (< 5)

**Przyczyny i rozwiÄ…zania:**
1. **Za duÅ¼o punktÃ³w do rysowania** â†’ Zakomentuj pÄ™tlÄ™ rysujÄ…cÄ…
2. **Za wysoka rozdzielczoÅ›Ä‡** â†’ Zmniejsz fx, fy do 0.5
3. **Za duÅ¼o wykrywanych twarzy** â†’ Ogranicz max_face do 1
4. **SÅ‚aby komputer** â†’ RozwaÅ¼ uÅ¼ycie dlib zamiast mediapipe

### Problem: Model nie rozpoznaje emocji poprawnie

**MoÅ¼liwe przyczyny:**
1. **Za maÅ‚o danych treningowych** â†’ Potrzebujesz minimum 100 zdjÄ™Ä‡ na emocjÄ™
2. **Niezbalansowany zbiÃ³r** â†’ Ustaw samples_limit w train()
3. **ZÅ‚y kernel SVM** â†’ SprÃ³buj rÃ³Å¼nych kerneli (rbf, poly, linear)
4. **Potrzeba normalizacji** â†’ Ustaw scale=True

### Problem: Kamera siÄ™ nie uruchamia

**RozwiÄ…zanie:**
1. SprawdÅº czy kamera dziaÅ‚a w innych aplikacjach
2. ZmieÅ„ `cv2.VideoCapture(0)` na `cv2.VideoCapture(1)` (inna kamera)
3. Ustaw `image_mode = True` i testuj na zdjÄ™ciach

---

## ğŸ“– Dalsza nauka

### Polecane tematy do zgÅ‚Ä™bienia:

**Podstawy:**
1. Jak dziaÅ‚ajÄ… sieci neuronowe?
2. Co to jest uczenie nadzorowane vs nienadzorowane?
3. Jak dziaÅ‚a walidacja krzyÅ¼owa?

**Åšredniozaawansowane:**
1. Inne algorytmy klasyfikacji (Random Forest, Neural Networks)
2. Augmentacja danych treningowych
3. Metryki oceny modelu (accuracy, precision, recall, F1-score)

**Zaawansowane:**
1. Transfer learning z gotowych modeli (VGG, ResNet)
2. Real-time video stream optimization
3. Deployment na urzÄ…dzenia mobilne

### Polecane zasoby:

**Polskie:**
- Kursy machine learning na platformach edukacyjnych
- Grupy na Facebooku o AI/ML w Polsce
- Polskie blogi o data science

**Angielskie:**
- Dokumentacja scikit-learn: https://scikit-learn.org/
- MediaPipe dokumentacja: https://google.github.io/mediapipe/
- Kaggle tutorials: https://www.kaggle.com/learn

---

## ğŸ¯ Podsumowanie

Gratulacje! Teraz rozumiesz:
- âœ… Jak dziaÅ‚a system rozpoznawania emocji end-to-end
- âœ… RolÄ™ kaÅ¼dego moduÅ‚u w projekcie
- âœ… Jak trenowaÄ‡ i testowaÄ‡ model SVM
- âœ… Jak eksperymentowaÄ‡ z rÃ³Å¼nymi parametrami
- âœ… Jak rozwiÄ…zywaÄ‡ typowe problemy

**NastÄ™pne kroki:**
1. PrzeprowadÅº wszystkie eksperymenty z sekcji ğŸ”¬
2. SprÃ³buj poprawiÄ‡ dokÅ‚adnoÅ›Ä‡ modelu
3. Dodaj nowe funkcje (np. zapisywanie statystyk)
4. Podziel siÄ™ wynikami z innymi!

**PamiÄ™taj:** Nauka przez praktykÄ™ jest najwaÅ¼niejsza. Nie bÃ³j siÄ™ eksperymentowaÄ‡ i popeÅ‚niaÄ‡ bÅ‚Ä™dÃ³w!

---

## ğŸ“ Notatki i pytania

UÅ¼yj tej sekcji do zapisywania wÅ‚asnych obserwacji i pytaÅ„ podczas pracy z projektem:

```
Moje obserwacje:
-
-
-

Pytania do zbadania:
-
-
-

PomysÅ‚y na ulepszenia:
-
-
-
```

Powodzenia w nauce! ğŸš€
